{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf5CmXQCZyF1"
   },
   "source": [
    "# Step 4. Pre-Processing and Training Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2jue2jPGJlt"
   },
   "source": [
    "**The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   [Problem Identification](https://medium.com/@aiden.dataminer/the-data-science-method-problem-identification-6ffcda1e5152)\n",
    "\n",
    "2.   [Data Wrangling](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-data-collection-organization-and-definitions-d19b6ff141c4) \n",
    "  * Data Collection \n",
    "   * Data Organization\n",
    "  * Data Definition \n",
    "  * Data Cleaning\n",
    " \n",
    "3.   [Exploratory Data Analysis](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-exploratory-data-analysis-bc84d4d8d3f9)\n",
    " * Build data profile tables and plots\n",
    "        - Outliers & Anomalies\n",
    " * Explore data relationships\n",
    " * Identification and creation of features\n",
    "\n",
    "4.   [**Pre-processing and Training Data Development**](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-pre-processing-and-training-data-development-fd2d75182967)\n",
    "  * Create dummy or indicator features for categorical variables\n",
    "  * Standardize the magnitude of numeric features\n",
    "  * Split into testing and training datasets\n",
    "  * Apply scaler to the testing set\n",
    "5.   [Modeling](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-modeling-56b4233cad1b)\n",
    "  * Create dummy or indicator features for categorical variable\n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   [Documentation](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-documentation-c92c28bd45e6)\n",
    "\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8xfkAqqZyF2"
   },
   "source": [
    "Load the necessary packages as we did in step 3 and print out the current working directory just to confirm we are in the correct project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry6WPL5eZyF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jb/Development/courses/springboard/ds/Assignments/test/big-mountain-resort\n",
      "['Notebook_Step4.ipynb', 'Notebook_Step6.ipynb', 'Notebook_Step2.ipynb', '.DS_Store', 'LICENSE', 'Notebook_Step5.ipynb', 'models', 'Notebook_Step3.ipynb', 'README.md', '.gitignore', 'figures', '.ipynb_checkpoints', '.git', 'data']\n"
     ]
    }
   ],
   "source": [
    "#load python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "print(os.getcwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "630T-ogRZyF8"
   },
   "source": [
    "Load the csv file created in step 3, remember it should be saved inside the data subfolder and print the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMNbk0u3ZyF9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>state</th>\n",
       "      <th>summit_elev</th>\n",
       "      <th>vertical_drop</th>\n",
       "      <th>base_elev</th>\n",
       "      <th>trams</th>\n",
       "      <th>fastEight</th>\n",
       "      <th>fastSixes</th>\n",
       "      <th>fastQuads</th>\n",
       "      <th>quad</th>\n",
       "      <th>...</th>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <th>Snow_Making_ac</th>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <th>yearsOpen</th>\n",
       "      <th>averageSnowfall</th>\n",
       "      <th>AdultWeekday</th>\n",
       "      <th>AdultWeekend</th>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyeska Resort</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>3939</td>\n",
       "      <td>2500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaglecrest Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2600</td>\n",
       "      <td>1540</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>640.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilltop Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2090</td>\n",
       "      <td>294</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona Snowbowl</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>11500</td>\n",
       "      <td>2300</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>777.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunrise Park Resort</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>11100</td>\n",
       "      <td>1800</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name    state  summit_elev  vertical_drop  base_elev  trams  \\\n",
       "0       Alyeska Resort   Alaska         3939           2500        250      1   \n",
       "1  Eaglecrest Ski Area   Alaska         2600           1540       1200      0   \n",
       "2     Hilltop Ski Area   Alaska         2090            294       1796      0   \n",
       "3     Arizona Snowbowl  Arizona        11500           2300       9200      0   \n",
       "4  Sunrise Park Resort  Arizona        11100           1800       9200      0   \n",
       "\n",
       "   fastEight  fastSixes  fastQuads  quad  ...  SkiableTerrain_ac  \\\n",
       "0        0.0          0          2     2  ...             1610.0   \n",
       "1        0.0          0          0     0  ...              640.0   \n",
       "2        0.0          0          0     0  ...               30.0   \n",
       "3        0.0          1          0     2  ...              777.0   \n",
       "4        0.0          0          1     2  ...              800.0   \n",
       "\n",
       "   Snow_Making_ac  daysOpenLastYear  yearsOpen  averageSnowfall  AdultWeekday  \\\n",
       "0           113.0             150.0       60.0            669.0          65.0   \n",
       "1            60.0              45.0       44.0            350.0          47.0   \n",
       "2            30.0             150.0       36.0             69.0          30.0   \n",
       "3           104.0             122.0       81.0            260.0          89.0   \n",
       "4            80.0             115.0       49.0            250.0          74.0   \n",
       "\n",
       "   AdultWeekend  projectedDaysOpen  NightSkiing_ac  clusters  \n",
       "0          85.0              150.0           550.0         1  \n",
       "1          53.0               90.0             0.0         1  \n",
       "2          34.0              152.0            30.0         1  \n",
       "3          89.0              122.0             0.0         0  \n",
       "4          78.0              104.0            80.0         0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/step3_output.csv')\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>state</th>\n",
       "      <th>summit_elev</th>\n",
       "      <th>vertical_drop</th>\n",
       "      <th>base_elev</th>\n",
       "      <th>trams</th>\n",
       "      <th>fastEight</th>\n",
       "      <th>fastSixes</th>\n",
       "      <th>fastQuads</th>\n",
       "      <th>quad</th>\n",
       "      <th>...</th>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <th>Snow_Making_ac</th>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <th>yearsOpen</th>\n",
       "      <th>averageSnowfall</th>\n",
       "      <th>AdultWeekday</th>\n",
       "      <th>AdultWeekend</th>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Whitefish Mountain Resort</td>\n",
       "      <td>Montana</td>\n",
       "      <td>6817</td>\n",
       "      <td>2353</td>\n",
       "      <td>4464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name    state  summit_elev  vertical_drop  \\\n",
       "151  Whitefish Mountain Resort  Montana         6817           2353   \n",
       "\n",
       "     base_elev  trams  fastEight  fastSixes  fastQuads  quad  ...  \\\n",
       "151       4464      0        0.0          0          3     2  ...   \n",
       "\n",
       "     SkiableTerrain_ac  Snow_Making_ac  daysOpenLastYear  yearsOpen  \\\n",
       "151             3000.0           600.0             123.0       72.0   \n",
       "\n",
       "     averageSnowfall  AdultWeekday  AdultWeekend  projectedDaysOpen  \\\n",
       "151            333.0          81.0          81.0              123.0   \n",
       "\n",
       "     NightSkiing_ac  clusters  \n",
       "151           600.0         2  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Name'].str.contains('Whitefish')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkBHf9smZyGB"
   },
   "source": [
    "## Create dummy features for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWKHm0NhAnrJ"
   },
   "source": [
    "Create dummy variables for `state`. Addes the dummies back to the dataframe and remove the original column for `state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZqWk8ltZyGZ"
   },
   "outputs": [],
   "source": [
    "df_awe_m1 = pd.concat([df.drop(['state'], axis=1), pd.get_dummies(df['state'])], axis=1)\n",
    "# df_awe_m1 = df.drop(['summit_elev','base_elev', 'clusters'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>summit_elev</th>\n",
       "      <th>vertical_drop</th>\n",
       "      <th>base_elev</th>\n",
       "      <th>trams</th>\n",
       "      <th>fastEight</th>\n",
       "      <th>fastSixes</th>\n",
       "      <th>fastQuads</th>\n",
       "      <th>quad</th>\n",
       "      <th>triple</th>\n",
       "      <th>...</th>\n",
       "      <th>Rhode Island</th>\n",
       "      <th>South Dakota</th>\n",
       "      <th>Tennessee</th>\n",
       "      <th>Utah</th>\n",
       "      <th>Vermont</th>\n",
       "      <th>Virginia</th>\n",
       "      <th>Washington</th>\n",
       "      <th>West Virginia</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Wyoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyeska Resort</td>\n",
       "      <td>3939</td>\n",
       "      <td>2500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eaglecrest Ski Area</td>\n",
       "      <td>2600</td>\n",
       "      <td>1540</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilltop Ski Area</td>\n",
       "      <td>2090</td>\n",
       "      <td>294</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona Snowbowl</td>\n",
       "      <td>11500</td>\n",
       "      <td>2300</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunrise Park Resort</td>\n",
       "      <td>11100</td>\n",
       "      <td>1800</td>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name  summit_elev  vertical_drop  base_elev  trams  \\\n",
       "0       Alyeska Resort         3939           2500        250      1   \n",
       "1  Eaglecrest Ski Area         2600           1540       1200      0   \n",
       "2     Hilltop Ski Area         2090            294       1796      0   \n",
       "3     Arizona Snowbowl        11500           2300       9200      0   \n",
       "4  Sunrise Park Resort        11100           1800       9200      0   \n",
       "\n",
       "   fastEight  fastSixes  fastQuads  quad  triple  ...  Rhode Island  \\\n",
       "0        0.0          0          2     2       0  ...             0   \n",
       "1        0.0          0          0     0       0  ...             0   \n",
       "2        0.0          0          0     0       1  ...             0   \n",
       "3        0.0          1          0     2       2  ...             0   \n",
       "4        0.0          0          1     2       3  ...             0   \n",
       "\n",
       "   South Dakota  Tennessee  Utah  Vermont  Virginia  Washington  \\\n",
       "0             0          0     0        0         0           0   \n",
       "1             0          0     0        0         0           0   \n",
       "2             0          0     0        0         0           0   \n",
       "3             0          0     0        0         0           0   \n",
       "4             0          0     0        0         0           0   \n",
       "\n",
       "   West Virginia  Wisconsin  Wyoming  \n",
       "0              0          0        0  \n",
       "1              0          0        0  \n",
       "2              0          0        0  \n",
       "3              0          0        0  \n",
       "4              0          0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_awe_m1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnDVhE1-ZyGF"
   },
   "source": [
    "## Standardize the magnitude of numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gW3D-WlDZyGG"
   },
   "source": [
    "Using sklearn preprocessing standardize the scale of the features of the dataframe except the name of the resort which we done't need in the dataframe for modeling, so it can be droppped here as well. Also, we want to hold out our response variable(s) so we can have their true values available for model performance review. Let's set `AdultWeekend` to the y variable as our response for scaling and modeling. Later we will go back and consider the `AdultWeekday`, `dayOpenLastYear`, and `projectedDaysOpen`. For now leave them in the development dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict `AdultWeekend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we import the preprocessing package from the sklearn library\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# The standardizing of the features will happen many time so the fuction below \n",
    "# handles the standardiziation of features\n",
    "def standardize_features(x):\n",
    "    # Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "    scaler = preprocessing.StandardScaler().fit(x)\n",
    "    # Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "    X_scaled = scaler.transform(x)\n",
    "    # return X_scaled\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZL-q-KtAYI6"
   },
   "outputs": [],
   "source": [
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X = df_awe_m1.drop(['Name','AdultWeekend', 'summit_elev','base_elev', 'clusters'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df_awe_m1.AdultWeekend\n",
    "\n",
    "X_scaled = standardize_features(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAT8h4_mZyGK"
   },
   "source": [
    "## Split into training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rdS8EGeAnrW"
   },
   "source": [
    "Using sklearn model selection import train_test_split, and create a 75/25 split with the y = `AdultWeekend`. We will start by using the adult weekend ticket price as our response variable for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSkPut0gguds"
   },
   "outputs": [],
   "source": [
    "# Import the train_test_split function from the sklearn.model_selection utility.  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The splitting of the dataframe will happen many time so the fuction below \n",
    "# handles the splitting the data into X_train, X_test, y_train, y_test given the 75/25 ratio split.\n",
    "def split_data(x, y):\n",
    "    # Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "    y = y.ravel()\n",
    "\n",
    "    # Call the train_test_split() function with the first two parameters set to x and y \n",
    "    # Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "    return  X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = split_data(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UayqbwkWAnra"
   },
   "source": [
    "Here we start the actual modeling work. First let's fit a multiple linear regression model to predict the `AdultWeekend` price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83fkLldXFCNd"
   },
   "source": [
    "# Step 5. Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbZXsVevfr9M"
   },
   "source": [
    "This is the fifth step in the Data Science Method. In the previous steps we cleaned and prepared the datasets. Now it's time to get into the most exciting part: modeling! In this exercise, we'll build three different models and compare each model's performance. In the end, we'll choose the best model for demonstrating insights to Big Mountain management.\n",
    "\n",
    "\n",
    "**The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   [Problem Identification](https://medium.com/@aiden.dataminer/the-data-science-method-problem-identification-6ffcda1e5152)\n",
    "\n",
    "2.   [Data Wrangling](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-data-collection-organization-and-definitions-d19b6ff141c4) \n",
    "  * Data Collection \n",
    "   * Data Organization\n",
    "  * Data Definition \n",
    "  * Data Cleaning\n",
    " \n",
    "3.   [Exploratory Data Analysis](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-exploratory-data-analysis-bc84d4d8d3f9)\n",
    " * Build data profile tables and plots\n",
    "        - Outliers & Anomalies\n",
    " * Explore data relationships\n",
    " * Identification and creation of features\n",
    "\n",
    "4.   [Pre-processing and Training Data Development](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-pre-processing-and-training-data-development-fd2d75182967)\n",
    "  * Create dummy or indicator features for categorical variables\n",
    "  * Standardize the magnitude of numeric features\n",
    "  * Split into testing and training datasets\n",
    "  * Apply scaler to the testing set\n",
    "5.   [**Modeling**](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-modeling-56b4233cad1b)\n",
    "  * Create dummy or indicator features for categorical variable\n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   [Documentation](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-documentation-c92c28bd45e6)\n",
    "\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D_wfsP_-Anra"
   },
   "source": [
    "## Fit Models with a Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CoI8S5SwAnrc"
   },
   "source": [
    "Using sklearn, fit the model on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "lm = LinearRegression()\n",
    "rfr = RandomForestRegressor(random_state=0, n_estimators=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_GFr8sRAnrd"
   },
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW6K7uOPAnre"
   },
   "outputs": [],
   "source": [
    "model_awe_1 = lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fHqz9-WAnrg"
   },
   "source": [
    "Predict on the testing dataset and score the model performance with the y_test set and the y-pred values. The explained variance is a measure of the variation explained by the model. This is also known as the R-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIo01lFEAnrh"
   },
   "outputs": [],
   "source": [
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_awe_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4YS0WE2Anrk"
   },
   "source": [
    "## Review Model Outcomes — Iterate over additional models as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSh9sGIYAnrk"
   },
   "outputs": [],
   "source": [
    "# You might want to use the explained_variance_score() and mean_absolute_error() metrics.\n",
    "# To do so, you will need to import them from sklearn.metrics. \n",
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error\n",
    "\n",
    "# The evaluation of the models will happen many time so the fuction below \n",
    "# handles model evaluation with explained variance score and mean absolute error\n",
    "def model_evaluate(y_test, y_pred):\n",
    "    evs = explained_variance_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print('Explained Variance Score: ', round(evs, 3))\n",
    "    print('Mean Absolute Error: ', round(mae, 3))\n",
    "    return evs, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  0.942\n",
      "Mean Absolute Error:  4.891\n"
     ]
    }
   ],
   "source": [
    "evs_awe_1, mae_awe_1 = model_evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWJcOuSdAnrr"
   },
   "source": [
    "Prints the intercept value from the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WzWejn6Anrt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.09440259526306\n"
     ]
    }
   ],
   "source": [
    "print(model_awe_1.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edajrenAAnrv"
   },
   "source": [
    "The intercept is the mean `AdultWeekend` price for all the resorts given the other characteristics. The addition or subtraction of each of the coefficient values in the regression are numeric adjustments applied to the intercept to provide a particular observation's value for the resulting `AdultWeekend` value. Also, because we took the time to scale our x values in the training data, we can compare each of the coeeficients for the features to determine the feature importances. \n",
    "\n",
    "Prints the coefficient values from the linear model and sort in descending order to identify the top ten most important features. Makes sure to review the absolute value of the coefficients, because the adjustment may be positive or negative, but what we are looking for is the magnitude of impact on our response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEKc_lmZAnrw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_chairs</th>\n",
       "      <td>4.517275e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastQuads</th>\n",
       "      <td>1.712509e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>1.604493e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>1.413938e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple</th>\n",
       "      <td>1.261330e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>1.022261e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastSixes</th>\n",
       "      <td>5.076742e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trams</th>\n",
       "      <td>4.362078e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>4.118177e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>3.886441e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficient\n",
       "total_chairs  4.517275e+13\n",
       "fastQuads     1.712509e+13\n",
       "surface       1.604493e+13\n",
       "double        1.413938e+13\n",
       "triple        1.261330e+13\n",
       "quad          1.022261e+13\n",
       "fastSixes     5.076742e+12\n",
       "trams         4.362078e+12\n",
       "New York      4.118177e+12\n",
       "Michigan      3.886441e+12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient']).sort_values(by='Coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpdALMoAAnry"
   },
   "source": [
    "We should see that the top ten important features contain different states. However, the state is not something the managers at the Big Mountain Resort can do anything about. Given that we care more about actionable traits associated with ticket pricing, rebuild the model without the state features and compare the results.\n",
    "\n",
    "Hint: Try to construct another model using exactly the steps we followed above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mHYA1BzAnrz"
   },
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pz1YXAdiAnr0"
   },
   "outputs": [],
   "source": [
    "# Start fresh \n",
    "df_awe_m2 = df.copy()\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name', 'state' and 'AdultWeekend' from the df\n",
    "X = df_awe_m2.drop(['Name', 'state', 'AdultWeekend'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df_awe_m2.AdultWeekend\n",
    "\n",
    "X_scaled = standardize_features(X) \n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nM1EGf16Anr2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  0.924\n",
      "Mean Absolute Error:  5.427\n",
      "64.05984328521328\n"
     ]
    }
   ],
   "source": [
    "model_awe_2 = lm.fit(X_train, y_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_awe_2.predict(X_test)\n",
    "\n",
    "evs_awe_2, mae_awe_2 = model_evaluate(y_test, y_pred)\n",
    "print(model_awe_2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdultWeekday</th>\n",
       "      <td>20.043081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit_elev</th>\n",
       "      <td>13.937355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_elev</th>\n",
       "      <td>10.748810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_drop</th>\n",
       "      <td>4.839792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>averageSnowfall</th>\n",
       "      <td>1.525115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>1.521778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple</th>\n",
       "      <td>1.418922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runs</th>\n",
       "      <td>1.331539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>1.259977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <td>1.037355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Coefficient\n",
       "AdultWeekday        20.043081\n",
       "summit_elev         13.937355\n",
       "base_elev           10.748810\n",
       "vertical_drop        4.839792\n",
       "averageSnowfall      1.525115\n",
       "quad                 1.521778\n",
       "triple               1.418922\n",
       "Runs                 1.331539\n",
       "surface              1.259977\n",
       "daysOpenLastYear     1.037355"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient']).sort_values(by='Coefficient', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWjQLr3LAnr6"
   },
   "source": [
    "When reviewing our new model coefficients, we see `summit_elev` is now in the number three spot. This is also difficult to change from a management prespective and highly correlated with `summit_elev` and `base_elev`.  This time, rebuild the model without the state features and without the `summit_elev` and without `base_elev`and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXqvcn93Anr7"
   },
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eugnDNNAnr8"
   },
   "outputs": [],
   "source": [
    "# Start fresh \n",
    "df_awe_m3 = df\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name', 'state', 'AdultWeekend', and 'summit_elev', from the df\n",
    "X = df_awe_m3.drop(['Name', 'state', 'AdultWeekend', 'summit_elev'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df_awe_m3.AdultWeekend\n",
    "\n",
    "X_scaled = standardize_features(X) \n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pq0pW7G9Anr_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  0.93\n",
      "Mean Absolute Error:  5.23\n",
      "64.06317276743371\n"
     ]
    }
   ],
   "source": [
    "model_awe_3 = lm.fit(X_train, y_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_awe_3.predict(X_test)\n",
    "\n",
    "evs_awe_3, mae_awe_3 = model_evaluate(y_test, y_pred)\n",
    "print(model_awe_3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reXlf0HAAnsG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdultWeekday</th>\n",
       "      <td>20.011979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_drop</th>\n",
       "      <td>1.496063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>averageSnowfall</th>\n",
       "      <td>1.486591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>1.477121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runs</th>\n",
       "      <td>1.454351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple</th>\n",
       "      <td>1.398586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>1.200811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <td>1.084806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_elev</th>\n",
       "      <td>0.975561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <td>0.860096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Coefficient\n",
       "AdultWeekday        20.011979\n",
       "vertical_drop        1.496063\n",
       "averageSnowfall      1.486591\n",
       "quad                 1.477121\n",
       "Runs                 1.454351\n",
       "triple               1.398586\n",
       "surface              1.200811\n",
       "daysOpenLastYear     1.084806\n",
       "base_elev            0.975561\n",
       "clusters             0.860096"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient']).sort_values(by='Coefficient', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXqvcn93Anr7"
   },
   "source": [
    "#### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start fresh \n",
    "df_awe_m4 = pd.concat([df.drop(['state'], axis=1), pd.get_dummies(df['state'])], axis=1)\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name', 'state', 'AdultWeekend', and 'summit_elev', from the df\n",
    "X = df_awe_m4.drop(['Name','AdultWeekend', 'summit_elev','base_elev', 'clusters'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df_awe_m4.AdultWeekend\n",
    "\n",
    "X_scaled = standardize_features(X) \n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW6K7uOPAnre",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  0.907\n",
      "Mean Absolute Error:  5.808\n",
      "                   Importance\n",
      "AdultWeekday         0.840008\n",
      "total_chairs         0.015910\n",
      "Snow_Making_ac       0.015194\n",
      "yearsOpen            0.011536\n",
      "Runs                 0.010734\n",
      "vertical_drop        0.009692\n",
      "TerrainParks         0.008492\n",
      "averageSnowfall      0.008453\n",
      "projectedDaysOpen    0.007792\n",
      "daysOpenLastYear     0.007588\n",
      "LongestRun_mi        0.007206\n",
      "SkiableTerrain_ac    0.007204\n",
      "quad                 0.005975\n",
      "fastQuads            0.005544\n",
      "triple               0.005128\n",
      "NightSkiing_ac       0.005055\n",
      "North Carolina       0.004484\n",
      "surface              0.004293\n",
      "double               0.004174\n",
      "Montana              0.001512\n",
      "California           0.001462\n",
      "Vermont              0.001128\n",
      "Tennessee            0.001086\n",
      "Michigan             0.001046\n",
      "New York             0.000965\n",
      "Idaho                0.000903\n",
      "Maryland             0.000846\n",
      "Connecticut          0.000778\n",
      "Virginia             0.000535\n",
      "Minnesota            0.000533\n",
      "Pennsylvania         0.000483\n",
      "Colorado             0.000482\n",
      "New Hampshire        0.000471\n",
      "fastSixes            0.000381\n",
      "New Mexico           0.000376\n",
      "Ohio                 0.000376\n",
      "Maine                0.000301\n",
      "West Virginia        0.000249\n",
      "Wisconsin            0.000212\n",
      "trams                0.000205\n",
      "Nevada               0.000181\n",
      "Massachusetts        0.000161\n",
      "Utah                 0.000150\n",
      "Indiana              0.000123\n",
      "Missouri             0.000120\n",
      "Washington           0.000117\n",
      "Wyoming              0.000080\n",
      "Oregon               0.000054\n",
      "Illinois             0.000053\n",
      "New Jersey           0.000046\n",
      "Alaska               0.000045\n",
      "Rhode Island         0.000028\n",
      "Iowa                 0.000024\n",
      "South Dakota         0.000018\n",
      "Arizona              0.000004\n",
      "fastEight            0.000004\n"
     ]
    }
   ],
   "source": [
    "model_awe_4 = rfr.fit(X_train, y_train)\n",
    "model_awe_4.score(X_test, y_test)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_awe_4.predict(X_test)\n",
    "\n",
    "evs_awe_4, mae_awe_4 = model_evaluate(y_test, y_pred)\n",
    "\n",
    "coff_m4 = pd.DataFrame(rfr.feature_importances_, X.columns, columns=['Importance'])\n",
    "print(coff_m4.sort_values('Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXqvcn93Anr7"
   },
   "source": [
    "#### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start fresh \n",
    "df_awe_m5 = df.copy()\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name', 'state', 'AdultWeekend', and 'summit_elev', from the df\n",
    "X = df_awe_m5.drop(['Name', 'state', 'AdultWeekend'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df_awe_m5.AdultWeekend\n",
    "\n",
    "X_scaled = standardize_features(X) \n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW6K7uOPAnre",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9107895218584501\n",
      "Explained Variance Score:  0.911\n",
      "Mean Absolute Error:  5.746\n",
      "                   Importance\n",
      "AdultWeekday         0.841119\n",
      "total_chairs         0.016499\n",
      "Snow_Making_ac       0.015016\n",
      "yearsOpen            0.010643\n",
      "Runs                 0.010372\n",
      "vertical_drop        0.010147\n",
      "base_elev            0.009333\n",
      "TerrainParks         0.008693\n",
      "projectedDaysOpen    0.008162\n",
      "LongestRun_mi        0.007588\n",
      "averageSnowfall      0.007443\n",
      "daysOpenLastYear     0.007294\n",
      "SkiableTerrain_ac    0.007267\n",
      "summit_elev          0.007228\n",
      "quad                 0.006193\n",
      "NightSkiing_ac       0.005515\n",
      "fastQuads            0.005434\n",
      "triple               0.005070\n",
      "surface              0.004617\n",
      "double               0.003979\n",
      "clusters             0.001596\n",
      "fastSixes            0.000593\n",
      "trams                0.000199\n",
      "fastEight            0.000000\n"
     ]
    }
   ],
   "source": [
    "model_awe_5 = rfr.fit(X_train, y_train)\n",
    "print(model_awe_5.score(X_test, y_test))\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_awe_5.predict(X_test)\n",
    "\n",
    "evs_awe_5, mae_awe_5 = model_evaluate(y_test, y_pred)\n",
    "\n",
    "coff_m5 = pd.DataFrame(rfr.feature_importances_, X.columns, columns=['Importance'])\n",
    "print(coff_m5.sort_values('Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXqvcn93Anr7"
   },
   "source": [
    "#### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start fresh \n",
    "df_awe_m6 = df.copy()\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name', 'state', 'AdultWeekend', and 'summit_elev', from the df\n",
    "X = df_awe_m6.drop(['Name', 'state', 'AdultWeekend', 'summit_elev'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df_awe_m6.AdultWeekend\n",
    "\n",
    "X_scaled = standardize_features(X) \n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW6K7uOPAnre",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9087046451030285\n",
      "Explained Variance Score:  0.909\n",
      "Mean Absolute Error:  5.793\n",
      "                   Importance\n",
      "AdultWeekday         0.839749\n",
      "total_chairs         0.016978\n",
      "Snow_Making_ac       0.015548\n",
      "base_elev            0.012715\n",
      "yearsOpen            0.011352\n",
      "Runs                 0.010934\n",
      "vertical_drop        0.010740\n",
      "TerrainParks         0.008675\n",
      "averageSnowfall      0.008098\n",
      "projectedDaysOpen    0.007923\n",
      "LongestRun_mi        0.007767\n",
      "daysOpenLastYear     0.007489\n",
      "SkiableTerrain_ac    0.006914\n",
      "quad                 0.006618\n",
      "fastQuads            0.005876\n",
      "NightSkiing_ac       0.005533\n",
      "triple               0.005442\n",
      "surface              0.004967\n",
      "double               0.004133\n",
      "clusters             0.001698\n",
      "fastSixes            0.000611\n",
      "trams                0.000241\n",
      "fastEight            0.000000\n"
     ]
    }
   ],
   "source": [
    "model_awe_6 = rfr.fit(X_train, y_train)\n",
    "print(model_awe_6.score(X_test, y_test))\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_awe_6.predict(X_test)\n",
    "\n",
    "evs_awe_6, mae_awe_6 = model_evaluate(y_test, y_pred)\n",
    "\n",
    "coff_m6 = pd.DataFrame(rfr.feature_importances_, X.columns, columns=['Importance'])\n",
    "print(coff_m6.sort_values('Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJvQMns6AnsI"
   },
   "source": [
    "## Identify the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LD7-3iLcAnsK"
   },
   "source": [
    "We review the model performances in the table below and choose the best model for proving insights to Big Mountain management about what features are driving ski resort lift ticket prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "Explained Variance:   0.9418302256922265\n",
      "Mean Absolute Error:  4.891004596047414\n",
      "\n",
      "Model 2:\n",
      "Explained Variance:   0.9244916305612476\n",
      "Mean Absolute Error:  5.4273095818580135\n",
      "\n",
      "Model 3:\n",
      "Explained Variance:   0.9303448843132529\n",
      "Mean Absolute Error:  5.230491183251202\n",
      "\n",
      "Model 4:\n",
      "Explained Variance:   0.9069943141371271\n",
      "Mean Absolute Error:  5.8080674949259\n",
      "\n",
      "Model 5:\n",
      "Explained Variance:   0.9108519835581262\n",
      "Mean Absolute Error:  5.745632334931096\n",
      "\n",
      "Model 6:\n",
      "Explained Variance:   0.9087392430754438\n",
      "Mean Absolute Error:  5.793215346547441\n"
     ]
    }
   ],
   "source": [
    "print('Model 1:')\n",
    "print('Explained Variance:  ', evs_awe_1)\n",
    "print('Mean Absolute Error: ', mae_awe_1)\n",
    "print()\n",
    "print('Model 2:')\n",
    "print('Explained Variance:  ', evs_awe_2)\n",
    "print('Mean Absolute Error: ', mae_awe_2)\n",
    "print()\n",
    "print('Model 3:')\n",
    "print('Explained Variance:  ', evs_awe_3)\n",
    "print('Mean Absolute Error: ', mae_awe_3)\n",
    "print()\n",
    "print('Model 4:')\n",
    "print('Explained Variance:  ', evs_awe_4)\n",
    "print('Mean Absolute Error: ', mae_awe_4)\n",
    "print()\n",
    "print('Model 5:')\n",
    "print('Explained Variance:  ', evs_awe_5)\n",
    "print('Mean Absolute Error: ', mae_awe_5)\n",
    "print()\n",
    "print('Model 6:')\n",
    "print('Explained Variance:  ', evs_awe_6)\n",
    "print('Mean Absolute Error: ', mae_awe_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "La5S9fRPAnsK"
   },
   "source": [
    "| Model | Explained Variance| Mean Absolute Error|Features Dropped|\n",
    "| --- | --- | --- | --- |\n",
    "| Linear Regressor  |   |   | \n",
    "| Model 1. | 0.941 | 4.891 | 'summit_elev','base_elev', 'clusters' |\n",
    "| Model 2. | 0.925 | 5.404 | 'state'|\n",
    "| Model 3. | 0.931 | 5.211 |'state', 'base_elev', 'summit_elev'|\n",
    "|   |   |   | \n",
    "| Random Forest Regressor  |   |   | \n",
    "| Model 4. | 0.906 | 5.808 | 'summit_elev','base_elev', 'clusters' |\n",
    "| Model 5. | 0.910 | 5.749 | 'state'|\n",
    "| Model 6. | 0.909 | 5.772 |'state', 'base_elev', 'summit_elev'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2c-zn7TAnsL"
   },
   "source": [
    "### `AdultWeekend` prediction\n",
    "Model Selection: Model 1\n",
    "\n",
    "Model 1, with all features, performed the best. This will provide the most accurate insights to the Big Mountain management decision on lift ticket prices. Model 1 with the `state` feature produced a higher explained variance than the other two models, showing that 94% of the variance in the `AdultWeekend` (y) can be explained by the linear relationship between the input features (X) and the output prediction `AdultWeekend` (y). The mean absolute error for model 1 is lower the other models at 4.966.\n",
    "\n",
    "While categorical variable features are extremely difficult to control, the `state` feature helped maintain a lower mean absolute error because it segmentized and analyzed the states were higher or lower prices.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict `AdultWeekday`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  0.932\n",
      "Mean Absolute Error:  5.344\n",
      "58.015599983428864\n"
     ]
    }
   ],
   "source": [
    "# Start fresh \n",
    "df_awd_m1 = df.copy()\n",
    "\n",
    "# Make dummy `state_`s and drop `state`\n",
    "df_awd_m1 = pd.concat([df_awd_m1.drop(['state'], axis=1), pd.get_dummies(df_awd_m1[['state']])], axis=1)\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X = df_awd_m1.drop(['Name', 'AdultWeekday', 'summit_elev','base_elev', 'clusters'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df_awd_m1.AdultWeekday\n",
    "\n",
    "# Standardize\n",
    "X_scaled = standardize_features(X) \n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)\n",
    "\n",
    "#  Train model\n",
    "model_awd_1 = lm.fit(X_train, y_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_awd_1.predict(X_test)\n",
    "\n",
    "evs_awd_1, mae_awd_1 = model_evaluate(y_test, y_pred)\n",
    "print(model_awd_1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  0.915\n",
      "Mean Absolute Error:  5.727\n",
      "58.07050182630486\n"
     ]
    }
   ],
   "source": [
    "## Start fresh \n",
    "df_awd_m2 = df.copy()\n",
    "\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name', 'AdultWeekend', and 'state' from the df\n",
    "X = df_awd_m2.drop(['Name', 'AdultWeekday', 'state'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df_awd_m2.AdultWeekday\n",
    "\n",
    "# Standardize\n",
    "X_scaled = standardize_features(X) \n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)\n",
    "\n",
    "#  Train model\n",
    "model_awd_2 = lm.fit(X_train, y_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_awd_2.predict(X_test)\n",
    "\n",
    "evs_awd_2, mae_awd_2 = model_evaluate(y_test, y_pred)\n",
    "print(model_awd_2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  0.918\n",
      "Mean Absolute Error:  5.601\n",
      "58.066984208429695\n"
     ]
    }
   ],
   "source": [
    "## Start fresh \n",
    "df_awd_m3 = df.copy()\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name', 'AdultWeekend', 'state', and 'summit_elev' from the df\n",
    "X = df_awd_m3.drop(['Name', 'AdultWeekday', 'state', 'summit_elev'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df_awd_m3.AdultWeekday\n",
    "\n",
    "# Standardize\n",
    "X_scaled = standardize_features(X) \n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)\n",
    "\n",
    "# Train model\n",
    "model_awd_3 = lm.fit(X_train, y_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_awd_3.predict(X_test)\n",
    "\n",
    "evs_awd_3, mae_awd_3 = model_evaluate(y_test, y_pred)\n",
    "print(model_awd_3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "Explained Variance:   0.9319839837628828\n",
      "Mean Absolute Error:  5.343511780990138\n",
      "\n",
      "Model 2:\n",
      "Explained Variance:   0.9146816770144183\n",
      "Mean Absolute Error:  5.727019249006059\n",
      "\n",
      "Model 3:\n",
      "Explained Variance:   0.9182691736896524\n",
      "Mean Absolute Error:  5.6006548696030976\n"
     ]
    }
   ],
   "source": [
    "print('Model 1:')\n",
    "print('Explained Variance:  ', evs_awd_1)\n",
    "print('Mean Absolute Error: ', mae_awd_1)\n",
    "print()\n",
    "print('Model 2:')\n",
    "print('Explained Variance:  ', evs_awd_2)\n",
    "print('Mean Absolute Error: ', mae_awd_2)\n",
    "print()\n",
    "print('Model 3:')\n",
    "print('Explained Variance:  ', evs_awd_3)\n",
    "print('Mean Absolute Error: ', mae_awd_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "La5S9fRPAnsK"
   },
   "source": [
    "|Model | Explained Variance| Mean Absolute Error|Features Dropped|\n",
    "| --- | --- | --- | --- |\n",
    "| Linear Regressor  |   |   | \n",
    "| Model 1. | 0.931 | 5.343 | 'summit_elev','base_elev', 'clusters' |\n",
    "| Model 2. | 0.914 | 5.745 | 'state'|\n",
    "| Model 3. | 0.918 | 5.616 |'state', 'base_elev', 'summit_elev'|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2c-zn7TAnsL"
   },
   "source": [
    "### `AdultWeekday` prediction\n",
    "Model Selection: Model 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict `projectedDaysOpen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  -0.228\n",
      "Mean Absolute Error:  15.449\n",
      "120.17855603091783\n"
     ]
    }
   ],
   "source": [
    "# Start fresh \n",
    "df_pdo_m1 = df.copy()\n",
    "\n",
    "# Make dummy `state_`s and drop `state`\n",
    "df_pdo_m1 = pd.concat([df_pdo_m1.drop(['state'], axis=1), pd.get_dummies(df_pdo_m1[['state']])], axis=1)\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'projectedDaysOpen' from the df\n",
    "X = df_pdo_m1.drop(['Name', 'projectedDaysOpen', 'summit_elev','base_elev', 'clusters'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the projectedDaysOpen column of the df \n",
    "y = df_pdo_m1.projectedDaysOpen\n",
    "\n",
    "# Standardize\n",
    "X_scaled = standardize_features(X) \n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)\n",
    "\n",
    "#  Train model\n",
    "model_pdo_1 = lm.fit(X_train, y_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_pdo_1.predict(X_test)\n",
    "\n",
    "evs_pdo_1, mae_pdo_1 = model_evaluate(y_test, y_pred)\n",
    "print(model_pdo_1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  -0.049\n",
      "Mean Absolute Error:  13.811\n",
      "120.16053365315938\n"
     ]
    }
   ],
   "source": [
    "# Start fresh \n",
    "df_pdo_m2 = df.copy()\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'projectedDaysOpen' from the df\n",
    "X = df_pdo_m2.drop(['Name', 'projectedDaysOpen', 'state', ], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the projectedDaysOpen column of the df \n",
    "y = df_pdo_m2.projectedDaysOpen\n",
    "\n",
    "# Standardize\n",
    "X_scaled = standardize_features(X) \n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)\n",
    "\n",
    "#  Train model\n",
    "model_pdo_2 = lm.fit(X_train, y_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_pdo_2.predict(X_test)\n",
    "\n",
    "evs_pdo_2, mae_pdo_2 = model_evaluate(y_test, y_pred)\n",
    "print(model_pdo_2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score:  -0.064\n",
      "Mean Absolute Error:  13.856\n",
      "120.16539099135309\n"
     ]
    }
   ],
   "source": [
    "# Start fresh \n",
    "df_pdo_m3 = df.copy()\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'projectedDaysOpen' from the df\n",
    "X = df_pdo_m3.drop(['Name', 'projectedDaysOpen', 'state', 'summit_elev'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the projectedDaysOpen column of the df \n",
    "y = df_pdo_m3.projectedDaysOpen\n",
    "\n",
    "# Standardize\n",
    "X_scaled = standardize_features(X) \n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = split_data(X_scaled, y)\n",
    "\n",
    "#  Train model\n",
    "model_pdo_3 = lm.fit(X_train, y_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model_pdo_3.predict(X_test)\n",
    "\n",
    "evs_pdo_3, mae_pdo_3 = model_evaluate(y_test, y_pred)\n",
    "print(model_pdo_3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "Explained Variance:   -0.22791399282251334\n",
      "Mean Absolute Error:  15.44886556966154\n",
      "\n",
      "Model 2:\n",
      "Explained Variance:   -0.04938168313610203\n",
      "Mean Absolute Error:  13.811375894432356\n",
      "\n",
      "Model 3:\n",
      "Explained Variance:   -0.06443561881378312\n",
      "Mean Absolute Error:  13.85622688415533\n"
     ]
    }
   ],
   "source": [
    "print('Model 1:')\n",
    "print('Explained Variance:  ', evs_pdo_1)\n",
    "print('Mean Absolute Error: ', mae_pdo_1)\n",
    "print()\n",
    "print('Model 2:')\n",
    "print('Explained Variance:  ', evs_pdo_2)\n",
    "print('Mean Absolute Error: ', mae_pdo_2)\n",
    "print()\n",
    "print('Model 3:')\n",
    "print('Explained Variance:  ', evs_pdo_3)\n",
    "print('Mean Absolute Error: ', mae_pdo_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Explained Variance | Mean Absolute Error | Features Dropped|\n",
    "| --- | --- | --- | --- |\n",
    "| Linear Regressor  |   |   | \n",
    "| Model 1. | -0.227 | 15.448 | 'summit_elev','base_elev', 'clusters' |\n",
    "| Model 2. | -0.041 | 13.738 | 'state'|\n",
    "| Model 3. | -0.056 | 13.775 |'state', 'base_elev', 'summit_elev'|"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RtEspslPZyGY",
    "s0DokMkAZyGc",
    "2iuitnKcZyHS",
    "iAWQxougZyHW",
    "ThMTimlBZyHZ",
    "QwZ-LkjXZyHt",
    "srtXEA3N4-Y9",
    "ChVreJupZyIA",
    "zDgSSsq1ZyID",
    "I3GYKWfi5Llg",
    "pmMvrhbI-viE",
    "ZXDPkW3UZyIX",
    "Dnc_vHQLZyId",
    "daJxuJ-dZyIg",
    "mAQ-oHiPZyIn",
    "hnGOsp3mZyIp"
   ],
   "name": "GuidedCapstoneStep5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "whitefish_spring",
   "language": "python",
   "name": "whitefish_spring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
